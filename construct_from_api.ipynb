{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import hashlib\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(params: dict) -> dict:\n",
    "    url = \"https://en.wikipedia.org/w/api.php\"\n",
    "    params[\"format\"] = \"json\"\n",
    "    response_json = requests.get(url, params=params).json()\n",
    "    return response_json\n",
    "\n",
    "def compute_md5(s) -> str:\n",
    "    return hashlib.md5(str(s).strip().encode('utf-8')).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_revisions(title: str, n: int, first_or_last: str) -> list:\n",
    "    revs = []\n",
    "    params = {}\n",
    "    params[\"action\"] = \"query\"\n",
    "    params[\"prop\"] = \"revisions\"\n",
    "    params[\"titles\"] = title\n",
    "    params[\"rvprop\"] = \"ids|timestamp|user|userid|parsedcomment|comment|roles\"\n",
    "    params[\"rvdir\"] = \"newer\" if first_or_last == \"first\" else \"older\"\n",
    "    params[\"rvlimit\"] = n\n",
    "    params[\"formatversion\"] = \"2\"\n",
    "    \n",
    "    # handles continuation when asking for more than 50 revisions\n",
    "    while len(revs) < n:\n",
    "        response = query(params)\n",
    "        i = 0\n",
    "        while len(revs) < n and i < len(response[\"query\"][\"pages\"][0][\"revisions\"]):\n",
    "            revs.append(response[\"query\"][\"pages\"][0][\"revisions\"][i])\n",
    "            i += 1\n",
    "        params[\"rvcontinue\"] = response[\"continue\"][\"rvcontinue\"]\n",
    "    \n",
    "    return revs\n",
    "\n",
    "def get_revisions_between_ids(title: str, fromid: int, toid: int) -> list:\n",
    "    revs = []\n",
    "    params = {}\n",
    "    params[\"action\"] = \"query\"\n",
    "    params[\"prop\"] = \"revisions\"\n",
    "    params[\"titles\"] = title\n",
    "    params[\"rvprop\"] = \"ids|timestamp|user|userid|parsedcomment|comment|roles\"\n",
    "    params[\"rvdir\"] = \"newer\"\n",
    "    params[\"rvstartid\"] = fromid\n",
    "    params[\"rvendid\"] = toid\n",
    "    params[\"formatversion\"] = \"2\"\n",
    "    \n",
    "    response = query(params)\n",
    "    \n",
    "    # handles continuation when asking for more than 50 revisions\n",
    "    i = 0\n",
    "    while len(revs) == 0 or revs[-1][\"revid\"] < toid:\n",
    "        response = query(params)\n",
    "        revs.append(response[\"query\"][\"pages\"][0][\"revisions\"][i])\n",
    "        if \"continue\" in response:\n",
    "            params[\"rvcontinue\"] = response[\"continue\"][\"rvcontinue\"]\n",
    "            print(\"More than 50 revisions requested. Sending another request...\")\n",
    "        i += 1\n",
    "    \n",
    "    return revs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370558637 370558591\n",
      "370558638 370558591\n",
      "273853 370558638\n",
      "273854 273853\n",
      "47328 273854\n",
      "47331 47328\n",
      "47534 47331\n",
      "55470 47534\n",
      "137104 55470\n",
      "217200 137104\n"
     ]
    }
   ],
   "source": [
    "a = get_n_revisions(\"Talk:Philosophy\", 10, \"first\")\n",
    "for el in a:\n",
    "    print(el[\"revid\"], el[\"parentid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_revision_diff(title: str, fromid: int, toid: int) -> dict:\n",
    "    params = {}\n",
    "    params[\"action\"] = \"compare\"\n",
    "    params[\"fromrev\"] = fromid\n",
    "    params[\"torev\"] = toid\n",
    "    return query(params)\n",
    "\n",
    "def compute_text_depth(text: str) -> int:\n",
    "    d = 0\n",
    "    while text[d] == \":\":\n",
    "        d += 1\n",
    "    return d\n",
    "\n",
    "def compute_reply_hash(accum: dict, reply_to_hash: str, reply_to_depth: int, this_depth: int) -> str:\n",
    "    if this_depth == 0: \n",
    "        return None\n",
    "    elif this_depth > reply_to_depth:\n",
    "        return reply_to_hash\n",
    "    else:\n",
    "        while reply_to_depth > this_depth:\n",
    "            try:\n",
    "                reply_to_hash = accum[\"hash_lookup\"][accum[reply_to_hash][\"reply_to\"]]\n",
    "                reply_to_depth -= 1\n",
    "            except:\n",
    "                # in the case that a high level comment is not stored\n",
    "                return None\n",
    "    \n",
    "def find_ultimate_hash(accum: dict, h: str) -> str:\n",
    "    while accum[\"hash_lookup\"][h] != h:\n",
    "        h = accum[\"hash_lookup\"][h]\n",
    "    return h\n",
    "\n",
    "def is_unedited_block(all_td: list) -> bool:\n",
    "    return len(all_td) == 4 and all_td[0] == all_td[2]\n",
    "\n",
    "def is_new_section_text(added_text: str) -> bool:\n",
    "    return ((added_text[:3] == \"===\" and added_text[-3:] == \"===\") or \\\n",
    "            (added_text[:2] == \"==\" and added_text[-2:] == \"==\"))\n",
    "\n",
    "def is_new_content_block(all_td: list) -> bool:\n",
    "    return (len(all_td) == 3 and all_td[0][\"class\"][0] == \"diff-empty\" and all_td[2][\"class\"][0] == \"diff-addedline\")\n",
    "\n",
    "def is_removal_block(all_td: list) -> bool:\n",
    "    return (len(all_td) == 3 and all_td[1][\"class\"][0] == \"diff-deletedline\" and all_td[2][\"class\"][0] == \"diff-empty\")\n",
    "\n",
    "def is_modification_block(all_td: list) -> bool:\n",
    "    return (len(all_td) == 4 and all_td[1][\"class\"][0] == \"diff-deletedline\" and all_td[3][\"class\"][0] == \"diff-addedline\")\n",
    "\n",
    "def is_line_number_block(all_td: list) -> bool:\n",
    "    return (len(all_td) == 2 and all_td[0][\"class\"][0] == \"diff-lineno\" and all_td[1][\"class\"][0] == \"diff-lineno\")\n",
    "\n",
    "\n",
    "# How does this script handle modification? \n",
    "#   Part of the accumulation dictionary is the \"hash_lookup\" table. This table stores the modified hashes of \n",
    "#   every block that has been added to accum and not removed. I may or may not decide to remove hashes on \n",
    "#   removal from the thread (likely will). This allows for consistency of information across revisions, however\n",
    "#   rare editing a comment is. Additionally, each dictionary in accum keeps track of which revisions edited it,\n",
    "#   whose length should be equal to the depth in hash_lookup\n",
    "\n",
    "def parse_diff(edits: list, diff: dict, accum: dict={'hash_lookup': {}, 'revisions': {}, 'blocks': {}}) -> dict:\n",
    "\n",
    "    if accum == {}:\n",
    "        accum[\"hash_lookup\"] = {}\n",
    "        accum[\"revisions\"] = {}\n",
    "        accum[\"blocks\"] = {}\n",
    "        \n",
    "    soup = BeautifulSoup(diff[\"compare\"][\"*\"])\n",
    "    this_rev = {}\n",
    "    hashed_text, block_depth, last_hash, last_depth = None, None, None, None\n",
    "    last_block_was_ingested = False\n",
    "    behavior = []\n",
    "    for tr in soup.find_all(\"tr\")[1:]:\n",
    "        all_td = tr.find_all(\"td\")\n",
    "        block = {}\n",
    "        \n",
    "        if is_unedited_block(all_td):  # no edit in this block [ASSUMPTION. Must test with modification of a single block]   \n",
    "            assert(all_td[1].get_text() == all_td[3].get_text())\n",
    "            unedited_text = str(all_td[1].get_text())\n",
    "            if len(unedited_text) > 0:\n",
    "                hashed_text = compute_md5(unedited_text)\n",
    "                block_depth = compute_text_depth(unedited_text)\n",
    "                if hashed_text not in accum[\"blocks\"]: # this old block has not yet been added to accum\n",
    "                    block[\"text\"] = unedited_text\n",
    "                    block[\"timestamp\"] = edits[0][\"timestamp\"]\n",
    "                    block[\"user\"] = None\n",
    "                    block[\"ingested\"] = False\n",
    "                    block[\"revisions\"] = [\"unknown\"]\n",
    "                    block[\"reply_chain\"] = [hashed_text]\n",
    "                    accum[\"blocks\"][hashed_text] = block\n",
    "                    accum[\"hash_lookup\"][hashed_text] = hashed_text\n",
    "                else:\n",
    "                    # unchanged block has already been added to accum\n",
    "                    pass\n",
    "                last_hash = hashed_text\n",
    "                last_depth = block_depth\n",
    "                last_block_was_ingested = False\n",
    "            else:\n",
    "                # unchanged block is empty, do not need to record\n",
    "                pass\n",
    "            \n",
    "            \n",
    "        elif is_new_content_block(all_td): # block includes new content\n",
    "            added_text = str(all_td[2].get_text())\n",
    "            hashed_text = compute_md5(added_text)\n",
    "            if len(added_text) > 0:\n",
    "                block[\"text\"] = added_text\n",
    "                block[\"timestamp\"] = edits[1][\"timestamp\"]\n",
    "                block[\"user\"] = edits[1][\"user\"]\n",
    "                block[\"ingested\"] = True\n",
    "                block[\"revisions\"] = [edits[1][\"revid\"]]\n",
    "\n",
    "                if is_new_section_text(added_text):\n",
    "                    behavior.append(\"create_section\")\n",
    "                    block[\"reply_chain\"] = [hashed_text]\n",
    "                else:\n",
    "                    behavior.append(\"add_comment\")\n",
    "                    block_depth = compute_text_depth(added_text)\n",
    "                    if last_block_was_ingested:\n",
    "                        block[\"reply_chain\"] = accum[\"blocks\"][last_hash][\"reply_chain\"].copy()\n",
    "                        block[\"reply_chain\"].append(hashed_text)\n",
    "                        accum[\"blocks\"][last_hash][\"is_followed\"] = True\n",
    "                    else:\n",
    "                        reply_to_hash = compute_reply_hash(accum, last_hash, last_depth, block_depth)\n",
    "                        if reply_to_hash is not None:\n",
    "                            block[\"reply_chain\"] = accum[\"blocks\"][reply_to_hash][\"reply_chain\"].copy()\n",
    "                            block[\"reply_chain\"].append(hashed_text)\n",
    "                        else:\n",
    "                            block[\"reply_chain\"] = [hashed_text]  \n",
    "                \n",
    "                accum[\"blocks\"][hashed_text] = block\n",
    "                accum[\"hash_lookup\"][hashed_text] = hashed_text\n",
    "                last_hash = hashed_text\n",
    "                last_depth = block_depth\n",
    "                last_block_was_ingested = True\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "        elif is_removal_block(all_td):    # block is removing some earlier block\n",
    "            removed_text = str(all_td[1].get_text())\n",
    "            if len(removed_text) > 0:\n",
    "                hashed_removal = compute_md5(removed_text)\n",
    "                try:\n",
    "                    del accum[\"blocks\"][hashed_removal]    # removes the comment from the record of utterances\n",
    "                    del accum[\"hash_lookup\"][hashed_removal]\n",
    "                except KeyError:\n",
    "                    print(\"-------------------------------\")\n",
    "                    print(\"did not have comment on record: \")\n",
    "                    print(removed_text)\n",
    "                    print(\"-------------------------------\")\n",
    "        \n",
    "        elif is_modification_block(all_td):\n",
    "            old_text = str(all_td[1].get_text())\n",
    "            old_hash = compute_md5(old_text)\n",
    "            new_text = str(all_td[3].get_text())\n",
    "            new_hash = compute_md5(new_text)\n",
    "            behavior.append(\"modify\")\n",
    "            \n",
    "            if old_hash in accum[\"blocks\"]:\n",
    "                assert(old_hash in accum[\"hash_lookup\"])\n",
    "                # NOTE: does not touch \"ingested\" or \"reply_chain\" elements of dictionary\n",
    "                block = accum[\"blocks\"].pop(old_hashed)\n",
    "                block[\"text\"] = new_text\n",
    "                block[\"timestamp\"] = edits[1][\"timestamp\"]\n",
    "                block[\"user\"] = edits[1][\"user\"]\n",
    "                block[\"revisions\"].append(edits[1][\"revid\"])\n",
    "                accum[\"blocks\"][new_hash] = block\n",
    "                accum[\"hash_lookup\"][new_hash] = new_hash\n",
    "                accum[\"hash_lookup\"][old_hash] = new_hash\n",
    "            else:\n",
    "                # weird case, someone edits comment that hasn't been seen\n",
    "                assert(old_hash not in accum[\"hash_lookup\"])\n",
    "                block = {}\n",
    "                block[\"text\"] = new_text\n",
    "                block[\"timestamp\"] = edits[1][\"timestamp\"]\n",
    "                block[\"user\"] = edits[1][\"user\"]\n",
    "                block[\"ingested\"] = False\n",
    "                block[\"revisions\"] = [\"unknown\", edits[1][\"revid\"]]\n",
    "                block[\"reply_chain\"] = [new_hash]\n",
    "                accum[\"blocks\"][new_hash] = block\n",
    "                accum[\"hash_lookup\"][new_hash] = new_hash      \n",
    "        elif not is_line_number_block(all_td):\n",
    "            print(all_td)\n",
    "            raise Exception(\"block has unknown behavior\")\n",
    "            \n",
    "            \n",
    "    this_rev[\"behavior\"] = behavior\n",
    "    revid = edits[1][\"revid\"]\n",
    "    accum[\"revisions\"][revid] = this_rev\n",
    "    \n",
    "    return accum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_accum(accum: dict) -> None:\n",
    "    for k, v in accum.items():\n",
    "        if k == \"hash_lookup\":\n",
    "            print(\"hash_lookup----------------\")\n",
    "            for k2, v2 in v.items():\n",
    "                print(k2 + \": \" + v2)\n",
    "            print(\"---------------------------\\n\")\n",
    "            \n",
    "        if k == \"blocks\":\n",
    "            print(\"blocks---------------------\")\n",
    "            for k2, v2 in v.items():\n",
    "                print(\"\\n\")\n",
    "                print(k2)\n",
    "                for k3, v3 in v2.items():\n",
    "                    print(k3, \":\", v3)\n",
    "            print(\"---------------------------\")\n",
    "        \n",
    "        if k == \"revisions\":\n",
    "            print(\"revisions------------------\")\n",
    "            for k2, v2 in v.items():\n",
    "                print(k2, \":\", v2)\n",
    "            print(\"---------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Simple response to comment](https://en.wikipedia.org/w/index.php?diff=3561919&oldid=3553760&title=Talk:Philosophy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "edit1 = 3553760\n",
    "edit2 = 3561919\n",
    "\n",
    "edits = get_revisions_between_ids(\"Talk:Philosophy\", edit1, edit2)\n",
    "diff = get_revision_diff(\"Talk:Philosophy\", edit1, edit2)\n",
    "parsed = parse_diff(edits, diff)\n",
    "# print_accum(parsed)\n",
    "\n",
    "remove_edit1 = 3112925\n",
    "remove_edit2 = 3112956"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Slightly coarse discourse - demonstrating correct recognition of reply, depth, and old comments](https://en.wikipedia.org/w/index.php?diff=4644488&oldid=4644398&title=Talk:Philosophy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "edit3 = 4644398\n",
    "edit4 = 4644478\n",
    "\n",
    "edits = get_revisions_between_ids(\"Talk:Philosophy\", edit3, edit4)\n",
    "diff = get_revision_diff(\"Talk:Philosophy\", edit3, edit4)\n",
    "parsed = parse_diff(edits, diff)\n",
    "# print_accum(parsed)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"--------------------------------------------------------------------\")\n",
    "print(\"\\n\")\n",
    "\n",
    "edit5 = 4644488\n",
    "\n",
    "edits = get_revisions_between_ids(\"Talk:Philosophy\", edit4, edit5)\n",
    "diff = get_revision_diff(\"Talk:Philosophy\", edit4, edit5)\n",
    "parsed = parse_diff(edits, diff)\n",
    "# print_accum(parsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Adding russian then having it removed - mildly bad behavior](https://en.wikipedia.org/w/index.php?diff=919321798&oldid=917895729&title=Talk:Philosophy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_russian = 917895729\n",
    "adds_russian = 919321798\n",
    "removes_russian = 922496879\n",
    "removes_more = 922496879\n",
    "\n",
    "edits = get_revisions_between_ids(\"Talk:Philosophy\", before_russian, adds_russian)\n",
    "diff = get_revision_diff(\"Talk:Philosophy\", before_russian, adds_russian)\n",
    "parsed = parse_diff(edits, diff)\n",
    "# print(parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "did not have comment on record: \n",
      "== Досуговые измышления. С чашкой. Чая. На пример ..  ==\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "did not have comment on record: \n",
      "\"В Научном Мире\" (старом) это слово называлось \"гипотеза\". \n",
      "-------------------------------\n",
      "-------------------------------\n",
      "did not have comment on record: \n",
      "Сейчас - \"корреляция\". В US требование к высоте потенциального барьера над неопределённостью типа \"50%/50%\" - 25%. \n",
      "-------------------------------\n",
      "-------------------------------\n",
      "did not have comment on record: \n",
      "У нас (в SU) .. в RU ? .. скоромно - 1%. Факт конешно упрямая вещь .. Но уровень инфлюэнций ожидаетца порядка 4% .. \n",
      "-------------------------------\n",
      "-------------------------------\n",
      "did not have comment on record: \n",
      "Хрен знат .. может и сделают перерасчёт пенсионов как обещали.  Хм .. ?? Ну и ладно! Вот и хорошо !! .. [[Special:Contributions/85.140.16.27|85.140.16.27]] ([[User talk:85.140.16.27|talk]]) 02:34, 3 October 2019 (UTC)\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "edits = get_revisions_between_ids(\"Talk:Philosophy\", adds_russian, removes_russian)\n",
    "diff = get_revision_diff(\"Talk:Philosophy\", adds_russian, removes_russian)\n",
    "parsed = parse_diff(edits, diff)\n",
    "# print(parsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "craft may have a problem with seeing multiple comments from one user in a row - it would be better to make the multiple blocks into one comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from: 2598506 to: 9670552\n",
      "hash_lookup----------------\n",
      "627a7e73df2711c1638b440538240dbc: 627a7e73df2711c1638b440538240dbc\n",
      "baea044d32c787353f49b168a215e098: baea044d32c787353f49b168a215e098\n",
      "0c0994fbd69e70162dfec4d84720a6ce: 0c0994fbd69e70162dfec4d84720a6ce\n",
      "18638d41e27ba80935fc902c6cda04b4: 18638d41e27ba80935fc902c6cda04b4\n",
      "8f1b8edc1950d2fbc708744ed21998d5: 8f1b8edc1950d2fbc708744ed21998d5\n",
      "e7aa9ebae9200b3f07a0d71015a86f25: e7aa9ebae9200b3f07a0d71015a86f25\n",
      "fd7c613608c2b8d0374eafe7f1315e5d: fd7c613608c2b8d0374eafe7f1315e5d\n",
      "84a722f8aa83d758ba184693b5bf18ab: 84a722f8aa83d758ba184693b5bf18ab\n",
      "6bc819c14a4fd9ca1f2c4615d76afe7e: 6bc819c14a4fd9ca1f2c4615d76afe7e\n",
      "23153fe236975b6406002d4fcf2fe58f: 23153fe236975b6406002d4fcf2fe58f\n",
      "fa8393644a675f496550df1b4284f005: fa8393644a675f496550df1b4284f005\n",
      "e72d7bfdfb81cbec2b02aec454621144: e72d7bfdfb81cbec2b02aec454621144\n",
      "7bd335b38f376df2c6091013b63ff309: 7bd335b38f376df2c6091013b63ff309\n",
      "00405040d54fbbe70ff606b2b56cedd4: 00405040d54fbbe70ff606b2b56cedd4\n",
      "31c4fd35e67ee39b6958629d2c535654: 31c4fd35e67ee39b6958629d2c535654\n",
      "3199204e873c58dc0bafa57663d372b1: 3199204e873c58dc0bafa57663d372b1\n",
      "0ffecc1aaed0428a94af5419cf5798f7: 0ffecc1aaed0428a94af5419cf5798f7\n",
      "7e6ee6684a9ac1d20ca0d66e77b004f6: 7e6ee6684a9ac1d20ca0d66e77b004f6\n",
      "a6c58a5ec67ce3746c057303208dd31d: a6c58a5ec67ce3746c057303208dd31d\n",
      "---------------------------\n",
      "\n",
      "revisions------------------\n",
      "5901737 : {'behavior': ['add_comment', 'create_section', 'add_comment', 'add_comment']}\n",
      "6982050 : {'behavior': ['create_section', 'add_comment', 'add_comment']}\n",
      "7194217 : {'behavior': ['create_section', 'add_comment']}\n",
      "8600560 : {'behavior': ['create_section', 'add_comment', 'add_comment']}\n",
      "8622939 : {'behavior': ['add_comment']}\n",
      "8622950 : {'behavior': ['add_comment']}\n",
      "9661109 : {'behavior': ['add_comment']}\n",
      "9662096 : {'behavior': ['create_section', 'add_comment']}\n",
      "9670552 : {'behavior': ['add_comment']}\n",
      "---------------------------\n",
      "\n",
      "blocks---------------------\n",
      "\n",
      "\n",
      "627a7e73df2711c1638b440538240dbc\n",
      "text : The 8 series is a 90s car, not an 80s car. The 6 series did not end production until 1989.  The 8 series was not introduced until 1990.\n",
      "timestamp : 2004-02-12T21:44:46Z\n",
      "user : None\n",
      "ingested : False\n",
      "revisions : ['unknown']\n",
      "reply_chain : ['627a7e73df2711c1638b440538240dbc']\n",
      "\n",
      "\n",
      "baea044d32c787353f49b168a215e098\n",
      "text : ----\n",
      "timestamp : 2004-03-02T15:36:41Z\n",
      "user : Akadruid\n",
      "ingested : True\n",
      "revisions : [5901737]\n",
      "reply_chain : ['baea044d32c787353f49b168a215e098']\n",
      "\n",
      "\n",
      "0c0994fbd69e70162dfec4d84720a6ce\n",
      "text : ==X5?==\n",
      "timestamp : 2004-03-02T15:36:41Z\n",
      "user : Akadruid\n",
      "ingested : True\n",
      "revisions : [5901737]\n",
      "reply_chain : ['0c0994fbd69e70162dfec4d84720a6ce']\n",
      "is_followed : True\n",
      "\n",
      "\n",
      "18638d41e27ba80935fc902c6cda04b4\n",
      "text : ''X5: BMW's first SUV, this vehicle has all the dynamic qualities expected of a BMW, and set new expectations for SUV design ''\n",
      "timestamp : 2004-03-02T15:36:41Z\n",
      "user : Akadruid\n",
      "ingested : True\n",
      "revisions : [5901737]\n",
      "reply_chain : ['0c0994fbd69e70162dfec4d84720a6ce', '18638d41e27ba80935fc902c6cda04b4']\n",
      "is_followed : True\n",
      "\n",
      "\n",
      "8f1b8edc1950d2fbc708744ed21998d5\n",
      "text : Is there any evidence to back this up? The X5 is highly limited soft-roader.  It is a poor vehicle both on and off road, and is sold purely on its image.  Even BMW admit the vehicle should be driven carefully due its poor handling.  From the company who built the [[BMW M5|M5]] and recently sold [[Land Rover]], this is a poor cash in. [[User:Akadruid|akaDruid]] 15:36, 2 Mar 2004 (UTC)\n",
      "timestamp : 2004-03-02T15:36:41Z\n",
      "user : Akadruid\n",
      "ingested : True\n",
      "revisions : [5901737]\n",
      "reply_chain : ['0c0994fbd69e70162dfec4d84720a6ce', '18638d41e27ba80935fc902c6cda04b4', '8f1b8edc1950d2fbc708744ed21998d5']\n",
      "\n",
      "\n",
      "e7aa9ebae9200b3f07a0d71015a86f25\n",
      "text : == BMW ==\n",
      "timestamp : 2004-09-15T13:46:20Z\n",
      "user : 195.97.195.66\n",
      "ingested : True\n",
      "revisions : [6982050]\n",
      "reply_chain : ['e7aa9ebae9200b3f07a0d71015a86f25']\n",
      "is_followed : True\n",
      "\n",
      "\n",
      "fd7c613608c2b8d0374eafe7f1315e5d\n",
      "text : Is also the initials of 70's reggae greats Bob Marley and the Wailers.\n",
      "timestamp : 2004-09-15T13:46:20Z\n",
      "user : 195.97.195.66\n",
      "ingested : True\n",
      "revisions : [6982050]\n",
      "reply_chain : ['e7aa9ebae9200b3f07a0d71015a86f25', 'fd7c613608c2b8d0374eafe7f1315e5d']\n",
      "is_followed : True\n",
      "\n",
      "\n",
      "84a722f8aa83d758ba184693b5bf18ab\n",
      "text : This association is still carried on today, indeed some youth sub-cultures refer to BMW as 'Black Mans Wheels'\n",
      "timestamp : 2004-09-15T13:46:20Z\n",
      "user : 195.97.195.66\n",
      "ingested : True\n",
      "revisions : [6982050]\n",
      "reply_chain : ['e7aa9ebae9200b3f07a0d71015a86f25', 'fd7c613608c2b8d0374eafe7f1315e5d', '84a722f8aa83d758ba184693b5bf18ab']\n",
      "\n",
      "\n",
      "6bc819c14a4fd9ca1f2c4615d76afe7e\n",
      "text : == Beemers ==\n",
      "timestamp : 2004-10-30T14:36:44Z\n",
      "user : Loganberry\n",
      "ingested : True\n",
      "revisions : [7194217]\n",
      "reply_chain : ['6bc819c14a4fd9ca1f2c4615d76afe7e']\n",
      "is_followed : True\n",
      "\n",
      "\n",
      "23153fe236975b6406002d4fcf2fe58f\n",
      "text : Here in the UK, the word \"Beemer\" is commonly used about the cars; I've virtually never seen \"Bimmer\" here. [[User:Loganberry|Loganberry]] 14:36, 30 Oct 2004 (UTC)\n",
      "timestamp : 2004-10-30T14:36:44Z\n",
      "user : Loganberry\n",
      "ingested : True\n",
      "revisions : [7194217]\n",
      "reply_chain : ['6bc819c14a4fd9ca1f2c4615d76afe7e', '23153fe236975b6406002d4fcf2fe58f']\n",
      "\n",
      "\n",
      "fa8393644a675f496550df1b4284f005\n",
      "text : == The BMW Bavaria? ==\n",
      "timestamp : 2004-11-07T19:03:48Z\n",
      "user : TJSwoboda\n",
      "ingested : True\n",
      "revisions : [8600560]\n",
      "reply_chain : ['fa8393644a675f496550df1b4284f005']\n",
      "is_followed : True\n",
      "\n",
      "\n",
      "e72d7bfdfb81cbec2b02aec454621144\n",
      "text : Maybe I should just do some research and add it myself, but nowhere in the article is the BMW Bavaria mentioned.  This model was the immediate predecessor to the 5-series, and was seen at the time (mid 70s) as combining the features of the 3.0 CS and another model I've forgotten, at a much cheaper price.  My dad had one, but being a toddler at the time my memory's a little fuzzy, and he wouldn't even let me drive it.\n",
      "timestamp : 2004-11-07T19:03:48Z\n",
      "user : TJSwoboda\n",
      "ingested : True\n",
      "revisions : [8600560]\n",
      "reply_chain : ['fa8393644a675f496550df1b4284f005', 'e72d7bfdfb81cbec2b02aec454621144']\n",
      "is_followed : True\n",
      "\n",
      "\n",
      "7bd335b38f376df2c6091013b63ff309\n",
      "text : [[User:TJSwoboda|TJSwoboda]] 19:03, 7 Nov 2004 (UTC)\n",
      "timestamp : 2004-11-07T19:03:48Z\n",
      "user : TJSwoboda\n",
      "ingested : True\n",
      "revisions : [8600560]\n",
      "reply_chain : ['fa8393644a675f496550df1b4284f005', 'e72d7bfdfb81cbec2b02aec454621144', '7bd335b38f376df2c6091013b63ff309']\n",
      "\n",
      "\n",
      "00405040d54fbbe70ff606b2b56cedd4\n",
      "text : :Same goes in Australia. - [[User:Vague Rant|Vague]] | [[User talk:Vague Rant|Rant]] 02:20, Dec 19, 2004 (UTC)\n",
      "timestamp : 2004-12-19T02:20:35Z\n",
      "user : Vague Rant\n",
      "ingested : True\n",
      "revisions : [8622939]\n",
      "reply_chain : ['6bc819c14a4fd9ca1f2c4615d76afe7e', '23153fe236975b6406002d4fcf2fe58f', '00405040d54fbbe70ff606b2b56cedd4']\n",
      "\n",
      "\n",
      "31c4fd35e67ee39b6958629d2c535654\n",
      "text : :: Sounds like it's regional, clearly.  In the US, that distinction goes back to the mid 70s, at least.  I'll clarify it. -- [[User:Baylink|Baylink]] 21:26, 19 Dec 2004 (UTC)\n",
      "timestamp : 2004-12-19T21:26:39Z\n",
      "user : Baylink\n",
      "ingested : True\n",
      "revisions : [8622950]\n",
      "reply_chain : ['6bc819c14a4fd9ca1f2c4615d76afe7e', '23153fe236975b6406002d4fcf2fe58f', '00405040d54fbbe70ff606b2b56cedd4', '31c4fd35e67ee39b6958629d2c535654']\n",
      "\n",
      "\n",
      "3199204e873c58dc0bafa57663d372b1\n",
      "text : : The history section could stand to be expanded *substantially*.  -- [[User:Baylink|Baylink]] 21:27, 19 Dec 2004 (UTC)\n",
      "timestamp : 2004-12-19T21:27:12Z\n",
      "user : Baylink\n",
      "ingested : True\n",
      "revisions : [9661109]\n",
      "reply_chain : ['fa8393644a675f496550df1b4284f005', 'e72d7bfdfb81cbec2b02aec454621144', '7bd335b38f376df2c6091013b63ff309', '3199204e873c58dc0bafa57663d372b1']\n",
      "\n",
      "\n",
      "0ffecc1aaed0428a94af5419cf5798f7\n",
      "text : == please add 2002tii ==\n",
      "timestamp : 2005-01-26T03:26:49Z\n",
      "user : BAxelrod\n",
      "ingested : True\n",
      "revisions : [9662096]\n",
      "reply_chain : ['0ffecc1aaed0428a94af5419cf5798f7']\n",
      "is_followed : True\n",
      "\n",
      "\n",
      "7e6ee6684a9ac1d20ca0d66e77b004f6\n",
      "text : the [[BMW 2002tii]] was an orphaned page.  It should probably be linked to from this or another relavent page.  Please someone with more knowledge on this subject add it where appropriate.  [[User:BAxelrod|BAxelrod]] 03:26, 26 Jan 2005 (UTC)\n",
      "timestamp : 2005-01-26T03:26:49Z\n",
      "user : BAxelrod\n",
      "ingested : True\n",
      "revisions : [9662096]\n",
      "reply_chain : ['0ffecc1aaed0428a94af5419cf5798f7', '7e6ee6684a9ac1d20ca0d66e77b004f6']\n",
      "\n",
      "\n",
      "a6c58a5ec67ce3746c057303208dd31d\n",
      "text : : I've linked it from the [[BMW New Class]] page and put it in the BMW Vehicles category, which is probably all it needs to be linked from.  The main BMW article has an odd layout (the cars are listed inline on the page instead of on a List of BMW Vehicles subpage) and there really isn't room to discuss derivations of the 2002 in the section on the page now.  Nevertheless, the 2002tii page still needs a whole ton of work, and I'm really not the person to take care of it. --[[User:Milkmandan|Milkmandan]] 04:08, 2005 Jan 26 (UTC)\n",
      "timestamp : 2005-01-26T04:08:28Z\n",
      "user : Milkmandan\n",
      "ingested : True\n",
      "revisions : [9670552]\n",
      "reply_chain : ['0ffecc1aaed0428a94af5419cf5798f7', '7e6ee6684a9ac1d20ca0d66e77b004f6', 'a6c58a5ec67ce3746c057303208dd31d']\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "def process_between_revisions(title: str, fromid: int, toid: int) -> dict:\n",
    "    assert(fromid != toid)\n",
    "    res = {}\n",
    "    revisions = get_revisions_between_ids(title, fromid, toid)\n",
    "    i = 1\n",
    "    while i < len(revisions):\n",
    "        last_rev = revisions[i-1]\n",
    "        curr_rev = revisions[i]\n",
    "        diff = get_revision_diff(title, last_rev[\"revid\"], curr_rev[\"revid\"])\n",
    "        res = parse_diff([last_rev, curr_rev], diff, res)\n",
    "        i += 1\n",
    "    return res\n",
    "\n",
    "a = get_n_revisions(\"Talk:BMW\", 10, \"first\")\n",
    "print(\"from:\",a[0][\"revid\"], \"to:\",a[-1][\"revid\"])\n",
    "\n",
    "res = process_between_revisions(\"Talk:BMW\", 2598506, 9670552)\n",
    "print_accum(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Badly behaved: commenting and creating new section after the comment](https://en.wikipedia.org/w/index.php?title=Talk:Philosophy&diff=next&oldid=3112956)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convokit import Corpus, User, Utterance\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # not in use\n",
    "def segment_contiguous_blocks(accum: dict, reply_chain: list) -> list:\n",
    "    if len(reply_chain) == 1:\n",
    "        return [[find_ultimate_hash(accum, reply_chain[0])]]\n",
    "    res = []\n",
    "    last_h = find_ultimate_hash(accum, reply_chain[0])\n",
    "    last_user = accum[\"blocks\"][last_h][\"user\"]\n",
    "    contig = [last_h]\n",
    "    for block in reply_chain[1:]:\n",
    "        this_h = find_ultimate_hash(accum, block)\n",
    "        this_user = accum[\"blocks\"][this_h][\"user\"]\n",
    "        if this_user == last_user:\n",
    "            contig.append(block)\n",
    "        else:\n",
    "            res.append(contig)\n",
    "            contig = [this_h]\n",
    "        last_h = this_h\n",
    "        last_user = this_user\n",
    "    if len(contig) > 0:\n",
    "        res.append(contig)\n",
    "    return res\n",
    "\n",
    "def string_of_seg(seg: list) -> str:\n",
    "    return ' '.join(seg)\n",
    "\n",
    "def print_segments(segments: list) -> None:\n",
    "    s = \"\"\n",
    "    for se in segments:\n",
    "        for h in se:\n",
    "            s += h[:8] + \" \"\n",
    "        s += \"| \"\n",
    "    print(s)\n",
    "\n",
    "def compute_utt_id_from_block_hashes(hashes: list, accum: dict) -> str:\n",
    "    # will improve later for defensibility against edits\n",
    "    return hashes[0]\n",
    "     \n",
    "def find_reply_to(segment: list) -> str:\n",
    "    if len(segment) == 1:\n",
    "        return None\n",
    "    else:\n",
    "        return segment[-2][0]\n",
    "    \n",
    "def convert_intermediate_to_convokit(accum: dict) -> Corpus:\n",
    "    users = {}\n",
    "    utterances = []\n",
    "    unknown_len = set()\n",
    "    complete_utterances = set()\n",
    "    block_hashes_to_segments = {}\n",
    "    block_hashes_to_utt_ids = {}\n",
    "    for block_hash, block in accum[\"blocks\"].items():\n",
    "        if block[\"user\"] not in users:\n",
    "            users[block[\"user\"]] = User(name = block[\"user\"])\n",
    "        segments = segment_contiguous_blocks(accum, block[\"reply_chain\"])\n",
    "        \n",
    "        for seg in segments[:-1]:\n",
    "            sos = string_of_seg(seg)\n",
    "            complete_utterances.add(sos)\n",
    "       \n",
    "        assert(block_hash == segments[-1][-1])\n",
    "        if \"is_followed\" not in accum[\"blocks\"][segments[-1][-1]]:\n",
    "            complete_utterances.add(string_of_seg(segments[-1]))\n",
    "        block_hashes_to_segments[block_hash] = segments\n",
    "#         print_segments(segments)\n",
    "        \n",
    "#     for el in iter(complete_utterances):\n",
    "#         t = \"\"\n",
    "#         for h in el.split(\" \"):\n",
    "#             t += accum[\"blocks\"][h][\"text\"][:15] + \" + \"\n",
    "#         print(t)\n",
    "    \n",
    "    for utt in iter(complete_utterances):\n",
    "        block_hashes = utt.split(\" \")\n",
    "        belongs_to_segment = block_hashes_to_segments[block_hashes[0]]\n",
    "        first_block = accum[\"blocks\"][block_hashes[0]]\n",
    "        \n",
    "        \n",
    "        u_id = block_hashes[0]\n",
    "        u_user = users[first_block[\"user\"]]\n",
    "        u_root = belongs_to_segment[0][0]\n",
    "        u_replyto = find_reply_to(belongs_to_segment)\n",
    "        u_timestamp = first_block[\"timestamp\"]\n",
    "        u_text = \"\\n\".join([accum[\"blocks\"][h][\"text\"] for h in block_hashes])\n",
    "        u_meta = {}\n",
    "        u_meta[\"constituent_blocks\"] = block_hashes\n",
    "        \n",
    "        for each_hash in block_hashes:\n",
    "            block_hashes_to_utt_ids[each_hash] = u_id\n",
    "            \n",
    "        this_utterance = Utterance(u_id, u_user, u_root, u_replyto, u_timestamp, u_text)\n",
    "        this_utterance.meta = u_meta\n",
    "        \n",
    "        utterances.append(this_utterance)\n",
    "    \n",
    "    corpus = Corpus(utterances=utterances)         \n",
    "    corpus.meta[\"reverse_block_index\"] = block_hashes_to_utt_ids\n",
    "    \n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "c = convert_intermediate_to_convokit(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6bc819c14a4fd9ca1f2c4615d76afe7e',\n",
       " 'fa8393644a675f496550df1b4284f005',\n",
       " 'baea044d32c787353f49b168a215e098',\n",
       " 'e7aa9ebae9200b3f07a0d71015a86f25',\n",
       " '0ffecc1aaed0428a94af5419cf5798f7',\n",
       " '0c0994fbd69e70162dfec4d84720a6ce',\n",
       " '627a7e73df2711c1638b440538240dbc']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.get_conversation_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Beemers ==\n",
      "Here in the UK, the word \"Beemer\" is commonly used about the cars; I've virtually never seen \"Bimmer\" here. [[User:Loganberry|Loganberry]] 14:36, 30 Oct 2004 (UTC)\n",
      " - :Same goes in Australia. - [[User:Vague Rant|Vague]] | [[User talk:Vague Rant|Rant]] 02:20, Dec 19, 2004 (UTC)\n",
      " -  - :: Sounds like it's regional, clearly.  In the US, that distinction goes back to the mid 70s, at least.  I'll clarify it. -- [[User:Baylink|Baylink]] 21:26, 19 Dec 2004 (UTC)\n",
      "\n",
      "\n",
      "== The BMW Bavaria? ==\n",
      "Maybe I should just do some research and add it myself, but nowhere in the article is the BMW Bavaria mentioned.  This model was the immediate predecessor to the 5-series, and was seen at the time (mid 70s) as combining the features of the 3.0 CS and another model I've forgotten, at a much cheaper price.  My dad had one, but being a toddler at the time my memory's a little fuzzy, and he wouldn't even let me drive it.\n",
      "[[User:TJSwoboda|TJSwoboda]] 19:03, 7 Nov 2004 (UTC)\n",
      " - : The history section could stand to be expanded *substantially*.  -- [[User:Baylink|Baylink]] 21:27, 19 Dec 2004 (UTC)\n",
      "\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "== BMW ==\n",
      "Is also the initials of 70's reggae greats Bob Marley and the Wailers.\n",
      "This association is still carried on today, indeed some youth sub-cultures refer to BMW as 'Black Mans Wheels'\n",
      "\n",
      "\n",
      "== please add 2002tii ==\n",
      "the [[BMW 2002tii]] was an orphaned page.  It should probably be linked to from this or another relavent page.  Please someone with more knowledge on this subject add it where appropriate.  [[User:BAxelrod|BAxelrod]] 03:26, 26 Jan 2005 (UTC)\n",
      " - : I've linked it from the [[BMW New Class]] page and put it in the BMW Vehicles category, which is probably all it needs to be linked from.  The main BMW article has an odd layout (the cars are listed inline on the page instead of on a List of BMW Vehicles subpage) and there really isn't room to discuss derivations of the 2002 in the section on the page now.  Nevertheless, the 2002tii page still needs a whole ton of work, and I'm really not the person to take care of it. --[[User:Milkmandan|Milkmandan]] 04:08, 2005 Jan 26 (UTC)\n",
      "\n",
      "\n",
      "==X5?==\n",
      "''X5: BMW's first SUV, this vehicle has all the dynamic qualities expected of a BMW, and set new expectations for SUV design ''\n",
      "Is there any evidence to back this up? The X5 is highly limited soft-roader.  It is a poor vehicle both on and off road, and is sold purely on its image.  Even BMW admit the vehicle should be driven carefully due its poor handling.  From the company who built the [[BMW M5|M5]] and recently sold [[Land Rover]], this is a poor cash in. [[User:Akadruid|akaDruid]] 15:36, 2 Mar 2004 (UTC)\n",
      "\n",
      "\n",
      "The 8 series is a 90s car, not an 80s car. The 6 series did not end production until 1989.  The 8 series was not introduced until 1990.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for conv in c.iter_conversations():\n",
    "    indent = \"\"\n",
    "    for utt in conv.iter_utterances():\n",
    "        print(indent + utt.text)\n",
    "        indent += \" - \"\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
